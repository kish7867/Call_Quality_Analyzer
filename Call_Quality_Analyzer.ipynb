{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŽ§ Call Quality Analyzer â€” Colab Notebook\n",
        "\n",
        "**What:** Analyze a sales call (YouTube) and return talk-time ratio,\n",
        "of questions, longest monologue, sentiment, and one actionable insight.  \n",
        "**Test file:** https://www.youtube.com/watch?v=4ostqJD3Psc  \n",
        "**Notes:** Uses lightweight models (Whisper tiny, Resemblyzer, VADER) so it runs on free Colab within the time limit.\n"
      ],
      "metadata": {
        "id": "q8ftVxr3YbIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "w-GOgKAjMuS3"
      },
      "outputs": [],
      "source": [
        "# Install dependencies (run once).\n",
        "# - yt-dlp: download YouTube audio\n",
        "# - faster-whisper: fast Whisper implementation\n",
        "# - resemblyzer: speaker embeddings\n",
        "# - librosa, soundfile: audio I/O\n",
        "# - nltk: sentiment (VADER)\n",
        "!pip -q install yt-dlp faster-whisper resemblyzer pydub librosa nltk scikit-learn webrtcvad soundfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# small helper imports & pipeline timer\n",
        "import time, json, os\n",
        "start_all = time.time()"
      ],
      "metadata": {
        "id": "Hpsf39QqT7Pv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1 â€” Download & prepare audio\n",
        "# We download the YouTube file and convert to 16kHz mono WAV (better for ASR & robust to noise).\n",
        "\n",
        "YT_URL=\"https://www.youtube.com/watch?v=4ostqJD3Psc\"\n",
        "!yt-dlp -f bestaudio -x --audio-format wav -o \"input.%(ext)s\" \"$YT_URL\"\n",
        "!ffmpeg -y -i input.wav -ac 1 -ar 16000 call_audio.wav -loglevel error\n",
        "# Optional: to trim long audio\n",
        "# !ffmpeg -y -t 600 -i input.wav -ac 1 -ar 16000 call_audio.wav -loglevel error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujz3MZTTUgEL",
        "outputId": "32ea9fc4-96f5-42b3-915d-84a98f024232"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=4ostqJD3Psc\n",
            "[youtube] 4ostqJD3Psc: Downloading webpage\n",
            "[youtube] 4ostqJD3Psc: Downloading tv simply player API JSON\n",
            "[youtube] 4ostqJD3Psc: Downloading tv client config\n",
            "[youtube] 4ostqJD3Psc: Downloading tv player API JSON\n",
            "[info] 4ostqJD3Psc: Downloading 1 format(s): 251\n",
            "[download] input.wav has already been downloaded\n",
            "[ExtractAudio] Destination: input.wav\n",
            "Deleting original file input.orig.wav (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faster_whisper import WhisperModel\n",
        "print(\"Transcription step: loading model (tiny.en) â€” this is optimized for CPU / free Colab\")\n",
        "t0 = time.time()\n",
        "model = WhisperModel(\"tiny.en\", compute_type=\"int8\")  # tiny.en + int8 = fast on CPU\n",
        "segments, info = model.transcribe(\"call_audio.wav\", word_timestamps=True, vad_filter=True)\n",
        "segments = list(segments)\n",
        "asr_time = time.time() - t0\n",
        "\n",
        "full_text = \" \".join([s.text.strip() for s in segments])\n",
        "print(f\"ASR done in {asr_time:.2f}s | language={info.language} | segments={len(segments)}\")\n",
        "print(\"Transcript preview:\", full_text[:500].replace(\"\\n\",\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcBQiTtwUmda",
        "outputId": "0472647a-e852-4e2f-f1da-a7be50bf46d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription step: loading model (tiny.en) â€” this is optimized for CPU / free Colab\n",
            "ASR done in 18.12s | language=en | segments=32\n",
            "Transcript preview: Thank you for calling Nissan. My name is Lauren. Can I have your name? Yeah, my name is John Smith. Thank you, John. How can I help you? I was just calling about to see how much it would cost to update the map in my car. I'd be happy to help you with that today. Did you receive a mailer from us? I did. Do you need the customer number? Yes, please. Okay. It's 1-5-2-4-3. Thank you. And the year making bottle of your vehicle? Yeah, I have a 2009 Nissan Altamond. Oh, nice car. Yeah, thank you. We re\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 â€” Diarization (Who spoke when)\n",
        "# We compute short overlapping audio windows â†’ speaker embeddings (Resemblyzer) â†’ KMeans(2) clustering â†’ merge adjacent windows to get speaker turns.\n",
        "\n",
        "import librosa, numpy as np\n",
        "from resemblyzer import VoiceEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load audio (16k mono)\n",
        "wav, sr = librosa.load(\"call_audio.wav\", sr=16000, mono=True)\n",
        "total_dur = len(wav) / sr\n",
        "\n",
        "# Window settings (empirically fast & accurate)\n",
        "win = 1.5   # seconds\n",
        "hop = 0.5   # seconds\n",
        "\n",
        "# Build frames\n",
        "frames = []\n",
        "t = 0.0\n",
        "while t < total_dur:\n",
        "    s = int(t*sr)\n",
        "    e = int(min((t+win)*sr, len(wav)))\n",
        "    if e - s >= int(0.3*sr):  # keep frames >= 300ms\n",
        "        frames.append((t, t+win, wav[s:e]))\n",
        "    t += hop\n",
        "\n",
        "# Quick energy-based VAD to skip silence frames\n",
        "def energy(x): return float(np.mean(x**2))\n",
        "energies = np.array([energy(f[2]) for f in frames])\n",
        "thr = np.percentile(energies, 60)  # keep top ~40% energy (heuristic)\n",
        "voiced_idx = np.where(energies >= thr)[0]\n",
        "voiced_frames = [frames[i] for i in voiced_idx]\n",
        "\n",
        "# Compute embeddings\n",
        "encoder = VoiceEncoder(device=\"cpu\")\n",
        "embs = [encoder.embed_utterance(x.astype(\"float32\")) for (_,_,x) in voiced_frames]\n",
        "\n",
        "# Cluster (fallback if too few embeddings)\n",
        "if len(embs) >= 2:\n",
        "    labels = KMeans(n_clusters=2, n_init=10, random_state=0).fit_predict(embs)\n",
        "else:\n",
        "    labels = [0] * len(embs)\n",
        "\n",
        "# Merge adjacent windows with same label to produce speaker turn segments\n",
        "speaker_segments = []\n",
        "for (s,e,_), lab in zip(voiced_frames, labels):\n",
        "    if not speaker_segments or lab != speaker_segments[-1][\"spk\"]:\n",
        "        speaker_segments.append({\"start\": s, \"end\": e, \"spk\": int(lab)})\n",
        "    else:\n",
        "        speaker_segments[-1][\"end\"] = e\n",
        "print(f\"Estimated speaker segments: {len(speaker_segments)} (approx)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0RzBCPwUzW2",
        "outputId": "e7498008-a40c-491c-9dc4-ffe81ddff73c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Estimated speaker segments: 20 (approx)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- talk-time & longest monologue ---\n",
        "talk_time = {0: 0.0, 1: 0.0}\n",
        "for seg in speaker_segments:\n",
        "    dur = seg[\"end\"] - seg[\"start\"]\n",
        "    talk_time[seg[\"spk\"]] += dur\n",
        "total = talk_time[0] + talk_time[1] + 1e-9\n",
        "ratio0 = 100.0 * talk_time[0] / total\n",
        "ratio1 = 100.0 * talk_time[1] / total\n",
        "longest = max((s[\"end\"]-s[\"start\"]) for s in speaker_segments) if speaker_segments else 0.0\n",
        "\n",
        "# --- question counting (hybrid) ---\n",
        "import re\n",
        "q_marks = full_text.count('?')\n",
        "interrogatives = set([\"what\",\"why\",\"how\",\"when\",\"where\",\"which\",\"who\",\"can\",\"could\",\"would\",\"will\",\"is\",\"are\",\"do\",\"does\",\"did\"])\n",
        "sentences = re.split(r'(?<=[\\.\\!\\?])\\s+', full_text.lower())\n",
        "extra_q = sum(1 for s in sentences if s.strip() and s.split()[0] in interrogatives and '?' not in s)\n",
        "num_questions = q_marks + extra_q\n",
        "\n",
        "# Print clean report\n",
        "report = {\n",
        "  \"talk_time_ratio\": {\"A\": round(ratio0,1), \"B\": round(ratio1,1)},\n",
        "  \"num_questions\": int(num_questions),\n",
        "  \"longest_monologue_sec\": round(longest,2),\n",
        "  \"transcript_preview\": full_text[:400].replace(\"\\n\",\" \")\n",
        "}\n",
        "\n",
        "import json\n",
        "print(\"=== Call Metrics ===\")\n",
        "print(json.dumps(report, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3unWBijPVKfJ",
        "outputId": "53fb95aa-8d71-4089-c7f6-6dfd8ceab088"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Call Metrics ===\n",
            "{\n",
            "  \"talk_time_ratio\": {\n",
            "    \"A\": 53.8,\n",
            "    \"B\": 46.2\n",
            "  },\n",
            "  \"num_questions\": 8,\n",
            "  \"longest_monologue_sec\": 13.0,\n",
            "  \"transcript_preview\": \"Thank you for calling Nissan. My name is Lauren. Can I have your name? Yeah, my name is John Smith. Thank you, John. How can I help you? I was just calling about to see how much it would cost to update the map in my car. I'd be happy to help you with that today. Did you receive a mailer from us? I did. Do you need the customer number? Yes, please. Okay. It's 1-5-2-4-3. Thank you. And the year maki\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon', quiet=True)\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "scores = sia.polarity_scores(full_text)\n",
        "compound = scores['compound']\n",
        "if compound >= 0.05: sentiment='positive'\n",
        "elif compound <= -0.05: sentiment='negative'\n",
        "else: sentiment='neutral'\n",
        "print(\"Sentiment:\", sentiment, scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_Kzbc3nVfUb",
        "outputId": "0e01d264-c188-4df1-e691-1f959d11003f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: positive {'neg': 0.006, 'neu': 0.75, 'pos': 0.244, 'compound': 0.997}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build insight using simple rules\n",
        "insights = []\n",
        "if ratio0 > 70 or ratio1 > 70:\n",
        "    insights.append(\"Talk-time is unbalanced (>70% by one speaker). Prompt the quieter speaker with open-ended questions.\")\n",
        "if (num_questions / max(0.01, (total_dur/60.0))) < 0.5:  # <0.5 q per minute â‰ˆ <5 per 10 mins\n",
        "    insights.append(\"Increase question density; ask more open-ended questions.\")\n",
        "if sentiment == \"negative\":\n",
        "    insights.append(\"Sentiment is negative: address objections early and confirm value.\")\n",
        "\n",
        "if not insights:\n",
        "    insights.append(\"Good balance detected. Close with a clear next step and timeline.\")\n",
        "\n",
        "rep = \"Speaker A\" if ratio0 >= ratio1 else \"Speaker B\"\n",
        "cust = \"Speaker B\" if rep == \"Speaker A\" else \"Speaker A\"\n",
        "\n",
        "final_report = {\n",
        "  \"talk_time_ratio\": {\"A\": round(ratio0,1), \"B\": round(ratio1,1)},\n",
        "  \"num_questions\": int(num_questions),\n",
        "  \"longest_monologue_sec\": round(longest,2),\n",
        "  \"sentiment\": sentiment,\n",
        "  \"insight\": insights[0],\n",
        "  \"bonus_guess\": {\"sales_rep\": rep, \"customer\": cust}\n",
        "}\n",
        "\n",
        "# Pretty print & save\n",
        "print(\"=== FINAL REPORT ===\")\n",
        "print(json.dumps(final_report, indent=2))\n",
        "\n",
        "# Save to JSON file\n",
        "outname = \"call_quality_results.json\"\n",
        "with open(outname, \"w\") as f:\n",
        "    json.dump(final_report, f, indent=2)\n",
        "print(\"Saved:\", outname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCufVpyTVmgR",
        "outputId": "8c0ff5da-ff96-4535-ae72-90369f2e255d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FINAL REPORT ===\n",
            "{\n",
            "  \"talk_time_ratio\": {\n",
            "    \"A\": 53.8,\n",
            "    \"B\": 46.2\n",
            "  },\n",
            "  \"num_questions\": 8,\n",
            "  \"longest_monologue_sec\": 13.0,\n",
            "  \"sentiment\": \"positive\",\n",
            "  \"insight\": \"Good balance detected. Close with a clear next step and timeline.\",\n",
            "  \"bonus_guess\": {\n",
            "    \"sales_rep\": \"Speaker A\",\n",
            "    \"customer\": \"Speaker B\"\n",
            "  }\n",
            "}\n",
            "Saved: call_quality_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total pipeline time (s):\", round(time.time() - start_all, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apUDBrb8VswO",
        "outputId": "42d280a8-756b-425b-fa03-0fc8e6da20bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pipeline time (s): 29.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Z8e9BFcIV2c2",
        "outputId": "a2bc4b22-8e0f-4b73-fefd-a5d3f58f2785"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_348df06a-0673-4d2d-87e7-dd507ba0e6b1\", \"call_quality_results.json\", 305)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
